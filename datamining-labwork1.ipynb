{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport json\nimport collections\nimport re, string\nimport sys\nimport time\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nfrom subprocess import check_output\nimport matplotlib.pyplot as plt\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-06T09:02:52.794207Z","iopub.execute_input":"2023-05-06T09:02:52.795047Z","iopub.status.idle":"2023-05-06T09:02:52.800896Z","shell.execute_reply.started":"2023-05-06T09:02:52.795014Z","shell.execute_reply":"2023-05-06T09:02:52.799311Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"code","source":"def read_json(file):\n    dataset = {}\n    keys = []\n    with open(file) as file_lines:\n        for count, line in enumerate(file_lines):\n            data = json.loads(line.strip())\n            if count ==0:\n                dataset, keys = init_ds(data)\n            for k in keys:\n                dataset[k].append(data[k])\n                \n        return pd.DataFrame(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:54:05.592268Z","iopub.execute_input":"2023-05-06T07:54:05.592619Z","iopub.status.idle":"2023-05-06T07:54:05.599632Z","shell.execute_reply.started":"2023-05-06T07:54:05.592590Z","shell.execute_reply":"2023-05-06T07:54:05.598761Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"yelp_review = read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\")\nyelp_review[\"date\"] = pd.to_datetime(yelp_review[\"date\"], format = \"%Y-%m-%d\")","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:54:05.601256Z","iopub.execute_input":"2023-05-06T07:54:05.602576Z","iopub.status.idle":"2023-05-06T07:55:39.076601Z","shell.execute_reply.started":"2023-05-06T07:54:05.602542Z","shell.execute_reply":"2023-05-06T07:55:39.075313Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"yelp_review.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:55:39.078331Z","iopub.execute_input":"2023-05-06T07:55:39.078635Z","iopub.status.idle":"2023-05-06T07:55:39.092454Z","shell.execute_reply.started":"2023-05-06T07:55:39.078609Z","shell.execute_reply":"2023-05-06T07:55:39.091489Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"                review_id                 user_id             business_id  \\\n0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n\n   stars  useful  funny  cool  \\\n0    3.0       0      0     0   \n1    5.0       1      0     1   \n2    3.0       0      0     0   \n3    5.0       1      0     1   \n4    4.0       1      0     1   \n\n                                                text                date  \n0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11  \n1  I've taken a lot of spin classes over the year... 2012-01-03 15:28:18  \n2  Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30  \n3  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03  \n4  Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>user_id</th>\n      <th>business_id</th>\n      <th>stars</th>\n      <th>useful</th>\n      <th>funny</th>\n      <th>cool</th>\n      <th>text</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KU_O5udG6zpxOg-VcAEodg</td>\n      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>If you decide to eat here, just be aware it is...</td>\n      <td>2018-07-07 22:09:11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>I've taken a lot of spin classes over the year...</td>\n      <td>2012-01-03 15:28:18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>saUsX_uimxRlCVr67Z4Jig</td>\n      <td>8g_iMtfSiwikVnbP2etR0A</td>\n      <td>YjUWPpI6HXG530lwP-fb2A</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n      <td>2014-02-05 20:30:30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AqPFMleE6RsU23_auESxiA</td>\n      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n      <td>2015-01-04 00:01:03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Cute interior and owner (?) gave us tour of up...</td>\n      <td>2017-01-14 20:54:15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"stopwords_set = set(['.','i','a','and','the','to', 'was', 'it', 'of', 'for', 'in', 'my', \n                 'that', 'so', 'do', 'our', 'the', 'and', ',', 'my', 'in', 'we', 'you', \n                 'are', 'is', 'be', 'me', 'like', 'get', 'time', 'place'])","metadata":{"execution":{"iopub.status.busy":"2023-05-06T08:13:13.107336Z","iopub.status.idle":"2023-05-06T08:13:13.107958Z","shell.execute_reply.started":"2023-05-06T08:13:13.107771Z","shell.execute_reply":"2023-05-06T08:13:13.107796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(s):\n    \"\"\"Convert string to lowercase and split into words (ignoring\n    punctuation), returning list of words.\n    \"\"\"\n    word_list = re.findall(r'\\w+', s.lower())\n    filtered_words = [word for word in word_list if word not in stopwords.words('english') and word not in stopwords_set]\n    return filtered_words\n\n\ndef count_ngrams(lines, min_length=1, max_length=1):\n    \"\"\"Iterate through given lines iterator (file object or list of\n    lines) and return n-gram frequencies. The return value is a dict\n    mapping the length of the n-gram to a collections.Counter\n    object of n-gram tuple and number of times that n-gram occurred.\n    Returned dict includes n-grams of length min_length to max_length.\n    \"\"\"\n    lengths = range(min_length, max_length + 1)\n    ngrams = {length: collections.Counter() for length in lengths}\n    queue = collections.deque(maxlen=max_length)\n\n    # Helper function to add n-grams at start of current queue to dict\n    def add_queue():\n        current = tuple(queue)\n        for length in lengths:\n            if len(current) >= length:\n                ngrams[length][current[:length]] += 1\n\n    # Loop through all lines and words and add n-grams to dict\n    for line in lines:\n        for word in tokenize(line):\n            queue.append(word)\n            if len(queue) >= max_length:\n                add_queue()\n\n    # Make sure we get the n-grams at the tail end of the queue\n    while len(queue) > min_length:\n        queue.popleft()\n        add_queue()\n\n    return ngrams\n\ndef print_most_frequent(ngrams, num=10):\n    \"\"\"Print num most common n-grams of each length in n-grams dict.\"\"\"\n    for n in sorted(ngrams):\n        print('----- {} most common {}-word phrase -----'.format(num, n))\n        for gram, count in ngrams[n].most_common(num):\n            print('{0}: {1}'.format(' '.join(gram), count))\n        print('')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:55:39.113007Z","iopub.execute_input":"2023-05-06T07:55:39.113814Z","iopub.status.idle":"2023-05-06T07:55:39.124683Z","shell.execute_reply.started":"2023-05-06T07:55:39.113789Z","shell.execute_reply":"2023-05-06T07:55:39.123710Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"markdown","source":"## Give out some common words in the reviews of 3 restaurants","metadata":{}},{"cell_type":"code","source":"num_business_analysis = 3 # basically this will tell how much computing and diverse our analysis will be\nyelp_business = read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\")","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:55:39.125573Z","iopub.execute_input":"2023-05-06T07:55:39.126344Z","iopub.status.idle":"2023-05-06T07:55:42.196927Z","shell.execute_reply.started":"2023-05-06T07:55:39.126319Z","shell.execute_reply":"2023-05-06T07:55:42.195516Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"business_ids= business_data[:num_business_analysis].business_id.values\nbusiness_names = business_data[:num_business_analysis][\"Business name\"].values\n# get all the reviews and analyse them\n#business_names\nfor i, business_id in enumerate(business_ids):\n    # now extract reviews from reviews data\n    print(\"Analysing business: \",business_names[i])\n    reviews = yelp_review.loc[yelp_review['business_id'] == business_id].text.values\n    most_used_text = count_ngrams(reviews,max_length=1)\n    print_most_frequent(most_used_text, num=10)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T07:55:42.198912Z","iopub.execute_input":"2023-05-06T07:55:42.199194Z","iopub.status.idle":"2023-05-06T07:55:50.835219Z","shell.execute_reply.started":"2023-05-06T07:55:42.199171Z","shell.execute_reply":"2023-05-06T07:55:50.833935Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"Analysing business:  Turning Point of North Wales\n----- 10 most common 1-word phrase -----\nfood: 176\nservice: 98\ncoffee: 83\ngood: 82\ntime: 81\nwait: 79\nplace: 77\ngreat: 76\nbreakfast: 71\nback: 69\n\nAnalysing business:  Body Cycle Spinning Studio\n----- 10 most common 1-word phrase -----\nclass: 232\nclasses: 160\ngreat: 140\nstudio: 140\ninstructors: 122\nbody: 113\ncycle: 111\nbikes: 100\nspinning: 100\nlove: 85\n\nAnalysing business:  Kettle Restaurant\n----- 10 most common 1-word phrase -----\nfood: 59\nbuffet: 58\ngood: 28\nplace: 28\nrestaurant: 28\nservice: 21\nbreakfast: 20\ngreat: 18\nfriendly: 17\nstaff: 16\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## TF/IDF","metadata":{}},{"cell_type":"code","source":"doc = yelp_review.text[0:10]\nunique = []\nfor line in doc:\n    words = tokenize(line)\n    for word in words:\n        if word not in unique:\n            unique.append(word) \nprint(unique)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-06T10:01:58.794342Z","iopub.execute_input":"2023-05-06T10:01:58.794738Z","iopub.status.idle":"2023-05-06T10:01:58.899825Z","shell.execute_reply.started":"2023-05-06T10:01:58.794710Z","shell.execute_reply":"2023-05-06T10:01:58.898221Z"},"trusted":true},"execution_count":364,"outputs":[{"name":"stdout","text":"['decide', 'eat', 'aware', 'going', 'take', '2', 'hours', 'beginning', 'end', 'tried', 'multiple', 'times', 'want', 'locations', 'nj', 'never', 'bad', 'experience', 'food', 'good', 'takes', 'long', 'time', 'come', 'waitstaff', 'young', 'usually', 'pleasant', 'many', 'experiences', 'spent', 'way', 'waiting', 'opt', 'another', 'diner', 'restaurant', 'weekends', 'order', 'done', 'quicker', 'taken', 'lot', 'spin', 'classes', 'years', 'nothing', 'compares', 'body', 'cycle', 'nice', 'clean', 'space', 'amazing', 'bikes', 'welcoming', 'motivating', 'instructors', 'every', 'class', 'top', 'notch', 'work', 'anyone', 'struggles', 'fit', 'workouts', 'online', 'scheduling', 'system', 'makes', 'easy', 'plan', 'ahead', 'need', 'line', 'advanced', 'gyms', 'make', 'write', 'review', 'without', 'giving', 'russell', 'owner', 'shout', 'passion', 'fitness', 'cycling', 'evident', 'desire', 'clients', 'succeed', 'always', 'dropping', 'check', 'provide', 'encouragement', 'open', 'ideas', 'recommendations', 'wears', 'smile', 'face', 'even', 'kicking', 'butt', 'family', 'buffet', 'eclectic', 'assortment', 'large', 'chicken', 'leg', 'fried', 'jalapeño', 'tamale', 'two', 'rolled', 'grape', 'leaves', 'fresh', 'melon', 'lots', 'mexican', 'choices', 'also', 'menu', 'breakfast', 'served', 'day', 'friendly', 'attentive', 'staff', 'place', 'casual', 'relaxed', 'meal', 'expectations', 'next', 'clarion', 'hotel', 'wow', 'yummy', 'different', 'delicious', 'favorite', 'lamb', 'curry', 'korma', '10', 'kinds', 'naan', 'let', 'outside', 'deter', 'almost', 'changed', 'minds', 'go', 'try', 'something', 'new', 'glad', 'cute', 'interior', 'gave', 'us', 'tour', 'upcoming', 'patio', 'rooftop', 'area', 'great', 'beautiful', 'days', 'today', 'cheese', 'curds', 'filling', 'really', 'sandwiches', 'w', 'salad', 'esp', 'eating', 'onion', 'gruyere', 'tomato', 'sandwich', 'much', 'liked', 'needed', 'else', 'pepper', 'jelly', 'maybe', 'would', 'see', 'options', 'added', 'salads', 'fun', 'cheeses', 'beer', 'wine', 'well', 'limited', 'cocktails', 'one', 'draft', 'wines', 'term', 'frequent', 'customer', 'establishment', 'went', '3', 'apps', 'told', 'busy', 'half', 'full', 'best', 'dick', 'reach', 'ass', 'yes', 'fuck', 'tipper', 'kanella', 'opened', 'back', 'dmitris', 'loved', 'grabbed', 'groupon', 'price', 'perfect', 'explore', 'orleans', 'someone', 'know', 'history', 'city', 'guide', 'tons', 'interesting', 'tidbits', 'enjoyed', 'highly', 'recommended', 'actually', 'thought', 'cemetery', 'took', 'around', 'french', 'quarter', 'first', 'hour', 'second', 'meet', 'front', 'grocery', 'store', 'seems', 'strange', 'terribly', 'hard', 'find', 'give', 'chance', 'water', 'stop', 'visitor', 'center', 'part', 'bathroom', 'break', 'parts', 'trip', 'amazingly', 'wings', 'homemade', 'bleu', 'ribeye', 'tender', 'perfectly', 'prepared', 'selection', 'craft', 'beers', 'definitely', 'recommend', 'checking', 'hidden', 'gem', 'easter', 'instead', 'lopez', 'lake', 'los', 'padres', 'national', 'forest', 'pretty', 'white', 'rock', 'needs', 'cut', 'dead', 'grass', 'invades', 'wish', 'rid', 'living', 'green', 'dirty', 'maintain', 'looking', 'dumpster', 'cachuma', 'looks', 'put', 'bit', 'effort', 'party', '6', 'hibachi', 'waitress', 'brought', 'separate', 'sushi', 'orders', 'plate', 'tell', 'forgot', 'several', 'items', 'understand', 'making', 'mistakes', 'restaraunt', 'quiet', 'kind', 'surprised', 'lively', 'cook', 'said', 'three', 'words', 'cooked', 'name', 'francisco', 'service', 'fishy', 'im', 'hoping', 'night', 'money']\n","output_type":"stream"}]},{"cell_type":"code","source":"word_count = {}\nfor word in unique:\n    count = 0\n    for line in doc:\n        words = tokenize(line)\n        count += words.count(word)\n    word_count[word] = count\n\n\ntf = {}\ntotal_words = sum(word_count.values())\nfor word, count in word_count.items():\n    tf[word] = count / total_words\n    \n    \nidf = {}\nnum_docs = len(doc)\nfor word in unique:\n    count = 0\n    for line in doc:\n        words = tokenize(line)\n        if word in words:\n            count += 1\n    idf[word] = math.log(num_docs / count)\n\ntf_idf = {}\nfor word, tf_value in tf.items():\n    tf_idf[word] = tf_value * idf[word]\n\ndf = pd.DataFrame({'Term': list(tf.keys()), 'TF': list(tf.values()), 'IDF': list(idf.values()), 'TF-IDF': list(tf_idf.values())})\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-06T10:09:13.765492Z","iopub.execute_input":"2023-05-06T10:09:13.766132Z","iopub.status.idle":"2023-05-06T10:10:19.276840Z","shell.execute_reply.started":"2023-05-06T10:09:13.766096Z","shell.execute_reply":"2023-05-06T10:10:19.275607Z"},"trusted":true},"execution_count":369,"outputs":[{"name":"stdout","text":"       Term        TF       IDF    TF-IDF\n0    decide  0.002083  2.302585  0.004797\n1       eat  0.002083  2.302585  0.004797\n2     aware  0.002083  2.302585  0.004797\n3     going  0.008333  0.916291  0.007636\n4      take  0.004167  1.609438  0.006706\n..      ...       ...       ...       ...\n356   fishy  0.002083  2.302585  0.004797\n357      im  0.002083  2.302585  0.004797\n358  hoping  0.002083  2.302585  0.004797\n359   night  0.002083  2.302585  0.004797\n360   money  0.002083  2.302585  0.004797\n\n[361 rows x 4 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}